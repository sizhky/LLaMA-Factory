### model
model_name_or_path: meta-llama/Llama-3.2-3B-Instruct
adapter_name_or_path: /home/paperspace/Code/LLaMA-Factory/saves/gommt/full/checkpoint-280
template: llama3
infer_backend: vllm
vllm_enforce_eager: true
infer_dtype: float16
cutoff_len: 8192
vllm_maxlen: 8192